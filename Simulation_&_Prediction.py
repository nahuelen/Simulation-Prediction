# -*- coding: utf-8 -*-
"""Actividad evaluación final clase 7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SxGCxx5BbbOGYuTCT-TKYhhnBUK8jtBr
"""

!pip install mplfinance

### importo librerias
import pandas as pd
import yfinance as yf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import mplfinance as mpf
from scipy.stats import chisquare

##descargo datos del banco galicia
galicia=yf.download('GGAL',start='2022-05-22', end='2024-05-22').reset_index()

galicia.head()

"""##1- Simulaciones"""

galicia['Date']=pd.to_datetime(galicia['Date'])
galicia = galicia.set_index('Date')

##Grafico de velas japonesas
mpf.plot(galicia, type='candle', style='charles', title='Gráfico de Velas Japonesas', ylabel='Precio', ylabel_lower='Volumen',figsize=(20, 8))

"""###Simulacion Precios del Subyacente"""

###
###analizo la distribucion
plt.figure(figsize=(12,6))
sns.histplot(galicia['Adj Close'], kde=True)##genero histograma
plt.title('Histograma Precio-Galcia')
plt.xlabel('Valor')
plt.ylabel('Frecuencia')
plt.show()

"""Se ve una clara asimetria derecha en el histograma"""

###analizo medidas con boxplot
plt.figure(figsize=(10, 6))
sns.boxplot(x=galicia['Adj Close'])
plt.title('Boxplot Precio Galicia')
plt.show()

# analizo valores descriptivos
descriptivo_precio=galicia['Adj Close'].describe()
print(descriptivo_precio)

### analizo asimetria y curtosis
asimetria = galicia['Adj Close'].skew()
curtosis = galicia['Adj Close'].kurt()

print(f"Asimetría: {asimetria}")
print(f"Curtosis: {curtosis}")

"""Como mostraba el histograma el coeficiente de asimetria mayor a 0 establece que existe una asimetria derecha, la curtosis positiva marca una distribucion leptocurtica con cola pesada y un pico mas alto, por el tipo de histograma voy a probar si sigue una distribucion chi cuadrado"""

# Calcula la prueba de chi-cuadrado
resultado_prueba = chisquare(galicia['Adj Close'])

# Imprime el resultado de la prueba de chi-cuadrado
print("Valor de chi-cuadrado:", resultado_prueba.statistic)
print("Valor p:", resultado_prueba.pvalue)

"""Al tener un p-valor menor al 0.05 rechazo la hipotesis nula por lo que la el precio no sigue una distribucion chi cuadrado en base a esto genero datos sinteticos con distribucion log normal con la media y desviacion de los datos historicos"""

###precios simulados
# Genero datos aleatorios utilizando una distribución lognormal
media_precio=galicia['Adj Close'].mean()
desv_precio=galicia['Adj Close'].std()

# Calcular los parámetros de la distribución normal subyacente
mu = np.log(media_precio**2 / np.sqrt(desv_precio**2 + media_precio**2))
sigma = np.sqrt(np.log(1 + (desv_precio**2 / media_precio**2)))

# Generar simulación log-normal
np.random.seed(36)  #
precios_sim = np.random.lognormal(mu,sigma,size=500000)

plt.figure(figsize=(12,6))
sns.histplot(precios_sim,kde=True)
plt.show()

print(precios_sim.mean())

# analizo valores descriptivos
print(precios_sim.min())

print(precios_sim.max())

"""###Simulacion Precios de ejercicio"""

######precios simulados
# Genero datos aleatorios utilizando una distribución lognormal
media_precio=galicia['Adj Close'].mean()
desv_precio=galicia['Adj Close'].std()

# Calcular los parámetros de la distribución normal subyacente
mu = np.log(media_precio**2 / np.sqrt(desv_precio**2 + media_precio**2))
sigma = np.sqrt(np.log(1 + (desv_precio**2 / media_precio**2)))

# Generar simulación log-normal
np.random.seed(37)  #
strike_sim = np.random.lognormal(mu,sigma,size=500000)
print(strike_sim)

plt.figure(figsize=(12,6))
sns.histplot(strike_sim,kde=True)
plt.show()

print(strike_sim.min())

print(strike_sim.max())

"""###Simulacion Tiempo al Vencimiento"""

# Defino el rango de la distribución uniforme (valores enteros entre 3 y 115) de acuerdo a informe de instituto argentino de mercadod e capitales
minimo = 3
maximo = 115

# Número de valores a generar
num_valores = 500000  # Por ejemplo, generaremos 500,000 valores

# Generar valores de la distribución uniforme
vencimiento_sim = np.random.randint(low=minimo, high=maximo+1, size=num_valores)
print(vencimiento_sim)

"""###Simulacion Volatilidad"""

galicia['Rendimiento'] = galicia['Adj Close'].pct_change()
print(galicia['Rendimiento'])

###analizo la distribucion
plt.figure(figsize=(12,6))
sns.histplot(galicia['Rendimiento'], kde=True)##genero histograma
plt.title('Histograma Rendimiento')
plt.xlabel('Valor')
plt.ylabel('Frecuencia')
plt.show()

#Calculo volatilidad
volatilidad=np.std(galicia['Rendimiento'])
print(volatilidad)

###simulo con chicuadrado
# Calcular los grados de libertad para la distribución chi-cuadrado
grados_libertad = len(galicia['Rendimiento']) - 1

# Número de simulaciones
num_simulaciones = 500000
np.random.seed(36)
# Generar muestras aleatorias de la distribución chi-cuadrado
chi_squared_samples = np.random.chisquare(df=grados_libertad, size=num_simulaciones)

# Ajustar las muestras para reflejar la volatilidad calculada
volatilidad_sim = np.sqrt(chi_squared_samples / grados_libertad) * volatilidad

# Imprimir algunos ejemplos de volatilidad generada
print(volatilidad_sim)

"""###Simulacion Tasa Libre de Riesgo"""

##extraigo dato de TNA de caucion de 52% a 30 dias y transformo a diaria exponencial
# Tasa nominal anual (en términos decimales)
tasa_anual = 0.52

### genero misma tasa
# Generar una serie de datos con la tasa fija
tasa_sim = np.full(500000, tasa_anual)

"""###Simulacion Tasa de Dividendos"""



"""###Simulacion Tipo de Operación: Compra / Venta"""

n = 1  # un ensayo por cada elemento (Bernoulli)
p = 0.5  # probabilidad de éxito

# Tamaño de la muestra
tamano_muestra = 500000
np.random.seed(37)
# Generar la muestra binomial
binomial_sample = np.random.binomial(n, p, tamano_muestra)

# Asignar valores de compra y venta a los resultados de la muestra binomial
# Si el resultado es 1, asignar valor compra, si es 0, asignar valor venta
compra_venta_sim = np.where(binomial_sample == 1, 'Compra', 'Venta')
print(compra_venta_sim)

"""###Simulacion Tipo de Opción: Call / Put"""

n = 1  # un ensayo por cada elemento (Bernoulli)
p = 0.5  # probabilidad de éxito

# Tamaño de la muestra
tamano_muestra = 500000
np.random.seed(36)
# Generar la muestra binomial
binomial_sample = np.random.binomial(n, p, tamano_muestra)

# Asignar valores de Call y Put a los resultados de la muestra binomial
# Si el resultado es 1, asignar call, si es 0, asignar put
call_put_sim = np.where(binomial_sample == 1, 'Call', 'Put')

print(call_put_sim)





"""###Simulacion Volumen"""

### genero histograma para ver la distribucion
plt.figure(figsize=(12,6))
sns.histplot(galicia['Volume'], kde=True)
plt.title('Histograma Volumen operado Galicia')
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.show()

##Analizo los datos descriptivos
desc_volumen=galicia['Volume'].describe()
print(desc_volumen)

"""De acuerdo al informe https://www.argentina.gob.ar/sites/default/files/2022.09._informe_de_gestion._geir-1.pdf de septimebre 2022 pag 29 el promedio operado de acciones fue de 44.440 millones y de opciones 2.862 millones, aplicamos la misma proporcion para obtener un valor aproximado."""

galicia['Volumen_op']=(2862/44440)*galicia['Volume']
print(galicia['Volumen_op'])

print(galicia['Volumen_op'].describe())

###Simulo el volumen en base a media y desvio de datos de mercado

# Genero datos aleatorios utilizando una distribución lognormal
media_precio=galicia['Volumen_op'].mean()
desv_precio=galicia['Volumen_op'].std()

# Calcular los parámetros de la distribución normal subyacente
mu = np.log(media_precio**2 / np.sqrt(desv_precio**2 + media_precio**2))
sigma = np.sqrt(np.log(1 + (desv_precio**2 / media_precio**2)))

# Generar simulación log-normal
np.random.seed(36)  #agrego semilla
volumen_sim = np.random.lognormal(mu,sigma,size=500000)
print(volumen_sim)

print(volumen_sim.mean())

print(volumen_sim.std())

print(type(volumen_sim))

"""###Simulacion Precio de la Opción: Call / Put"""

###Armo dataframe con datos anteriores simulados
df_sim={'Precio_subyacente': precios_sim,
        'Precio_ejercicio': strike_sim,
        'Vencimiento': vencimiento_sim,
        'Volatilidad': volatilidad_sim,
        'Tasa': tasa_sim,
        'Call_Put':call_put_sim,
        'Compra_Venta':compra_venta_sim
        }
df_sim=pd.DataFrame(df_sim)
df_sim.head(10)

###genero el precio de las opciones mediante el modelo de Black & Scholes
def black_scholes_call_price(S, X, T, r, sigma):
    """
    Calcula el precio de una opción de compra (call) usando el modelo de Black-Scholes.

    :param S: Precio actual del activo subyacente
    :param X: Precio de ejercicio
    :param T: Tiempo hasta el vencimiento (en años)
    :param r: Tasa de interés libre de riesgo
    :param sigma: Volatilidad del activo subyacente
    :return: Precio de la opción de compra (call)
    """
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    call_price = S * norm.cdf(d1) - X * np.exp(-r * T) * norm.cdf(d2)
    return call_price

def black_scholes_put_price(S, X, T, r, sigma):
    """
    Calcula el precio de una opción de venta (put) usando el modelo de Black-Scholes.

    :param S: Precio actual del activo subyacente
    :param X: Precio de ejercicio
    :param T: Tiempo hasta el vencimiento (en años)
    :param r: Tasa de interés libre de riesgo
    :param sigma: Volatilidad del activo subyacente
    :return: Precio de la opción de venta (put)
    """
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    put_price = X * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)
    return put_price

###Filtro datos de segun tipo de opcion
df_sim_call=df_sim[df_sim['Call_Put']=='Call']
df_sim_call.head(10)

df_sim_put=df_sim[df_sim['Call_Put']=='Put']
df_sim_put.head(10)

##Aplico los datos a calls
from scipy.stats import norm
#   :param S: Precio actual del activo subyacente
#   :param X: Precio de ejercicio
#   :param T: Tiempo hasta el vencimiento (en años)
#   :param r: Tasa de interés libre de riesgo
#   :param sigma: Volatilidad del activo subyacente
df_sim_call['Precio_opcion'] = df_sim_call.apply(
    lambda row: black_scholes_call_price(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_call.head(10)

##Aplico los datos a puts
#   :param S: Precio actual del activo subyacente
#   :param X: Precio de ejercicio
#   :param T: Tiempo hasta el vencimiento (en años)
#   :param r: Tasa de interés libre de riesgo
#   :param sigma: Volatilidad del activo subyacente
df_sim_put['Precio_opcion'] = df_sim_put.apply(
    lambda row: black_scholes_put_price(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_put.head(10)

print(df_sim_call['Precio_opcion'].min())

"""###Letras griegas"""

###defino formulas para para call
def delta(S, X, T, r, sigma):
    """
    Calcula Delta para una opción de compra (call) usando el modelo de Black-Scholes.

    :param S: Precio actual del activo subyacente
    :param X: Precio de ejercicio
    :param T: Tiempo hasta el vencimiento (en años)
    :param r: Tasa de interés libre de riesgo
    :param sigma: Volatilidad del activo subyacente
    :return: Delta de la opción de compra (call)
    """
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    delta = norm.cdf(d1)
    return delta

def gamma(S, X, T, r, sigma):
    """
    Calcula Gamma para una opción de compra (call) usando el modelo de Black-Scholes.

    :param S: Precio actual del activo subyacente
    :param X: Precio de ejercicio
    :param T: Tiempo hasta el vencimiento (en años)
    :param r: Tasa de interés libre de riesgo
    :param sigma: Volatilidad del activo subyacente
    :return: Gamma de la opción de compra (call)
    """
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    gamma = norm.pdf(d1) / (S * sigma * np.sqrt(T))
    return gamma

def vega(S, X, T, r, sigma):
    """
    Calcula Vega para una opción de compra (call) usando el modelo de Black-Scholes.

    :param S: Precio actual del activo subyacente
    :param X: Precio de ejercicio
    :param T: Tiempo hasta el vencimiento (en años)
    :param r: Tasa de interés libre de riesgo
    :param sigma: Volatilidad del activo subyacente
    :return: Vega de la opción de compra (call)
    """
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    vega = S * norm.pdf(d1) * np.sqrt(T)
    return vega

def rho(S, X, T, r, sigma):
    """
    Calcula Rho para una opción de compra (call) usando el modelo de Black-Scholes.

    :param S: Precio actual del activo subyacente
    :param X: Precio de ejercicio
    :param T: Tiempo hasta el vencimiento (en años)
    :param r: Tasa de interés libre de riesgo
    :param sigma: Volatilidad del activo subyacente
    :return: Rho de la opción de compra (call)
    """
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    rho = X * T * np.exp(-r * T) * norm.cdf(d2)
    return rho

def theta(S, X, T, r, sigma):
    """
    Calcula Theta para una opción de compra (call) usando el modelo de Black-Scholes.

    :param S: Precio actual del activo subyacente
    :param X: Precio de ejercicio
    :param T: Tiempo hasta el vencimiento (en años)
    :param r: Tasa de interés libre de riesgo
    :param sigma: Volatilidad del activo subyacente
    :return: Theta de la opción de compra (call)
    """
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    theta_call = -(S * norm.pdf(d1) * sigma) / (2 * np.sqrt(T)) - r * X * np.exp(-r * T) * norm.cdf(d2)
    return theta_call

df_sim_call['delta'] = df_sim_call.apply(
    lambda row: delta(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_call.head(10)

df_sim_call['gamma'] = df_sim_call.apply(
    lambda row: gamma(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_call.head(10)

df_sim_call['vega'] = df_sim_call.apply(
    lambda row: vega(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_call.head(10)

df_sim_call['rho'] = df_sim_call.apply(
    lambda row: rho(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_call.head(10)

df_sim_call['theta'] = df_sim_call.apply(
    lambda row: theta(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_call.head(10)

###defino los delta y theta de los puts
def delta(S, X, T, r, sigma):
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    delta_put = -norm.cdf(-d1)
    return delta_put
def rho(S, X, T, r, sigma):
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    rho_put = -X * T * np.exp(-r * T) * norm.cdf(-d2)
    return rho_put
def theta(S, X, T, r, sigma):
    d1 = (np.log(S / X) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))
    d2 = d1 - sigma * np.sqrt(T)
    theta_put = -(S * norm.pdf(d1) * sigma) / (2 * np.sqrt(T)) + r * X * np.exp(-r * T) * norm.cdf(-d2)
    return theta_put

df_sim_put['delta'] = df_sim_put.apply(
    lambda row: delta(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_put.head(10)

df_sim_put['gamma'] = df_sim_put.apply(
    lambda row: gamma(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_put.head(10)

df_sim_put['vega'] = df_sim_put.apply(
    lambda row: vega(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_put.head(10)

df_sim_put['rho'] = df_sim_put.apply(
    lambda row: rho(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_put.head(10)

df_sim_put['theta'] = df_sim_put.apply(
    lambda row: theta(row['Precio_subyacente'], row['Precio_ejercicio'],
                                         row['Vencimiento']/365, row['Tasa'], row['Volatilidad']),
    axis=1
)
df_sim_put.head(10)

"""##2- Entrenar redes"""

##Concateno los dataframe y ordemo por indice
df_sim=pd.concat([df_sim_call,df_sim_put])
df_sim=df_sim.sort_index()
df_sim.head(10)

"""Preparo Dataframe para aplicar modelos"""

pip install bayesian-optimization

###import librerias

from bayes_opt import BayesianOptimization
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df_sim = pd.get_dummies(df_sim, columns=["Call_Put",'Compra_Venta'])###transformo a dummies categoricos

X=pd.DataFrame.drop(df_sim, columns=['Precio_opcion'])
y=df_sim['Precio_opcion']

from sklearn.model_selection import train_test_split
X_temp,X_val,y_temp,y_val=train_test_split(X,y,test_size=0.2,random_state=36)
X_train,X_test,y_train,y_test=train_test_split(X_temp,y_temp,test_size=0.2,random_state=36)

###

# Funciones de escala basadas en Z-Score
scaler = StandardScaler()
scaler.fit(X_train)

X_scaled_train = scaler.transform(X_train)
X_scaled_vals = scaler.transform(X_val)
X_scaled_test = scaler.transform(X_test)
y_train = np.asarray(y_train)
y_val = np.asarray(y_val)
y_test = np.asarray(y_test)

"""###ANN"""

def modelo_ann (learning_rate, num_neurons):
  modelo=Sequential()
  modelo.add(Dense(int(num_neurons), activation='relu', input_shape=(X_train.shape[1],)))##agrego input y primera capa
  modelo.add(Dense(units=1, activation='linear'))## agrego capa de salida
  modelo.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')###compilo el modelo
  modelo.fit( X_scaled_train, y_train, epochs=10, batch_size=10000, verbose=0, validation_data=(X_scaled_vals, y_val))###entreon
  ##evaluo el modelo
  loss = modelo.evaluate(X_scaled_vals, y_val, verbose=0)
  return -loss # quiero minimizar el loss, por lo que devuelvo el negativo

###defino espacios de busqueda de hiperpareametros a optimizar
pbounds = {
    'learning_rate': (0.005,0.5),
    'num_neurons': (10,100)

}

###creo el optimizador bayesiano
optimizer = BayesianOptimization(
    f=modelo_ann,
    pbounds=pbounds,
    random_state=36,
    verbose=2
)

# Ejecutar la optimización
optimizer.maximize(
    init_points=10,
    n_iter=30
)

# Mejores parámetros encontrados
best_params = optimizer.max['params']
print("Mejores parámetros encontrados:", best_params)

modelo_ann=Sequential()
modelo_ann.add(Dense(int(best_params['num_neurons']), activation='relu', input_shape=(X_train.shape[1],)))##agrego input y primera capa
modelo_ann.add(Dense(units=1, activation='linear'))## agrego capa de salida
modelo_ann.compile(optimizer=Adam(learning_rate=best_params['num_neurons']), loss='mean_squared_error')###compilo el modelo
modelo_ann.fit( X_scaled_train, y_train, epochs=10, batch_size=100000, verbose=0, validation_data=(X_scaled_vals, y_val))###entreon

from sklearn import metrics
## predigo con datos de validacion
pred_ann=modelo_ann.predict(X_scaled_test)
###obtengo el error cuadratico medio
mse_ann=metrics.mean_squared_error(y_test,pred_ann)
print('Mean squared error:', mse_ann)

# Crear el gráfico de dispersión
plt.scatter(y_test, pred_ann, color='blue', label='Valores Predichos')

# Etiquetas y leyenda
plt.xlabel('Valores Reales')
plt.ylabel('Valores Predichos')
plt.title('Gráfico de Dispersión de Valores Reales vs. Valores Predichos por ANN')
plt.legend()

# Mostrar el gráfico
plt.show()

"""###MLP"""

def modelo_mlp (learning_rate, num_neurons,num_neurons1,num_neurons2,):
  modelo=Sequential()
  modelo.add(Dense(int(num_neurons), activation='relu', input_shape=(X_scaled_train.shape[1],)))##agrego input y primera capa
  modelo.add(Dense(int(num_neurons1), activation='relu'))
  modelo.add(Dense(int(num_neurons2), activation='relu'))
  modelo.add(Dense(units=1, activation='linear'))## agrego capa de salida
  modelo.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')###compilo el modelo
  modelo.fit( X_scaled_train, y_train, epochs=15, batch_size=10000, verbose=0, validation_data=(X_scaled_vals, y_val))###entreon
  ##evaluo el modelo
  loss = modelo.evaluate(X_scaled_vals, y_val, verbose=0)
  return -loss # quiero minimizar el loss, por lo que devuelvo el negativo

###defino espacios de busqueda de hiperpareametros a optimizar
pbounds = {
    'learning_rate': (0.005,0.1),
    'num_neurons': (10,100),
    'num_neurons1': (10,100),
    'num_neurons2': (5,10)

}

# Crear el optimizador bayesiano
optimizer = BayesianOptimization(
    f=modelo_mlp,
    pbounds=pbounds,
    random_state=36,
    verbose=2
)

# ejecuto la optimización
optimizer.maximize(
    init_points=10,
    n_iter=30
)
##mejores parametros
best_params = optimizer.max['params']
print("Mejores parámetros encontrados:", best_params)

modelo=Sequential()
modelo.add(Dense(int(best_params['num_neurons']), activation='relu', input_shape=(X_train.shape[1],)))##agrego input y primera capa
modelo.add(Dense(int(best_params['num_neurons1']), activation='relu'))
modelo.add(Dense(int(best_params['num_neurons2']), activation='relu'))
modelo.add(Dense(units=1, activation='linear'))## agrego capa de salida
modelo.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss='mean_squared_error')###compilo el modelo
modelo.fit( X_scaled_train, y_train, epochs=15, batch_size=10000, verbose=0, validation_data=(X_scaled_vals, y_val))###entreon
  ##evaluo el modelo
loss = modelo.evaluate(X_scaled_vals, y_val, verbose=0)

from sklearn import metrics
## predigo con datos de validacion
pred_mlp=modelo.predict(X_scaled_test)
###obtengo el error cuadratico medio
mse_mlp=metrics.mean_squared_error(y_test,pred_mlp)
print('Mean squared error:', mse_mlp)

# Crear el gráfico de dispersión
plt.scatter(y_test, pred_mlp, color='blue', label='Valores Predichos')

# Etiquetas y leyenda
plt.xlabel('Valores Reales')
plt.ylabel('Valores Predichos')
plt.title('Gráfico de Dispersión de Valores Reales vs. Valores Predichos por MLP Regresor')
plt.legend()

# Mostrar el gráfico
plt.show()

"""###LSTM"""

# Reformatear los datos para LSTM
X_train_lstm = X_scaled_train.reshape((X_scaled_train.shape[0], 1, X_scaled_train.shape[1]))
X_test_lstm=X_scaled_test.reshape((X_scaled_test.shape[0], 1, X_scaled_test.shape[1]))
X_val_lstm=X_scaled_vals.reshape((X_scaled_vals.shape[0], 1, X_scaled_vals.shape[1]))

import numpy as np
import json
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from bayes_opt import BayesianOptimization

# Función para crear y entrenar el modelo LSTM
def create_lstm_model(learning_rate, dropout_rate, lstm_units):
    model = Sequential()
    model.add(LSTM(units=int(lstm_units), input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True))
    model.add(Dropout(dropout_rate))
    model.add(LSTM(units=int(lstm_units)))
    model.add(Dropout(dropout_rate))
    model.add(Dense(1))

    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')

    model.fit(X_train_lstm, y_train, epochs=10, batch_size=10000, validation_data=(X_val_lstm, y_val), verbose=0)

    loss = model.evaluate(X_val_lstm, y_val, verbose=0)

    return -loss  # Devolver el negativo de la pérdida para minimizarla

# Definir el espacio de búsqueda
pbounds = {
    'learning_rate': (0.001, 0.1),
    'dropout_rate': (0.1, 0.7),
    'lstm_units': (10, 50)
}

# Crear el optimizador bayesiano
optimizer = BayesianOptimization(
    f=create_lstm_model,
    pbounds=pbounds,
    random_state=36,
    verbose=2
)

# Ejecutar la optimización
optimizer.maximize(
    init_points=10,
    n_iter=5
)

# Ver los mejores parámetros
best_params = optimizer.max['params']
print("Mejores parámetros encontrados:", best_params)

# Crear y entrenar el modelo final con los mejores hiperparámetros
best_model = Sequential()
best_model.add(LSTM(units=int(best_params['lstm_units']), input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), return_sequences=True))
best_model.add(Dropout(best_params['dropout_rate']))
best_model.add(LSTM(units=int(best_params['lstm_units'])))
best_model.add(Dropout(best_params['dropout_rate']))
best_model.add(Dense(1))

best_model.compile(optimizer=Adam(learning_rate=best_params['learning_rate']), loss='mean_squared_error')

best_model.fit(X_train_lstm, y_train, epochs=10, batch_size=10000, validation_data=(X_val_lstm, y_val), verbose=0)

from sklearn import metrics
## predigo con datos de validacion
pred_lstm=best_model.predict(X_test_lstm)
###obtengo el error cuadratico medio
mse_lstm=metrics.mean_squared_error(y_test,pred_lstm)
print('Mean squared error:', mse_lstm)

# Crear el gráfico de dispersión
plt.scatter(y_test, pred_lstm, color='blue', label='Valores Predichos')

# Etiquetas y leyenda
plt.xlabel('Valores Reales')
plt.ylabel('Valores Predichos')
plt.title('Gráfico de Dispersión de Valores Reales vs. Valores Predichos por LSTM Regresor')
plt.legend()

# Mostrar el gráfico
plt.show()